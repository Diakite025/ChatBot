# -*- coding: utf-8 -*-
"""chatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z0KYpRieSF8lSN89FpFjtFC3BxphRaQW
"""

from transformers import CamembertModel, CamembertTokenizer
import re
import torch
import random
from sklearn.preprocessing import LabelEncoder
import re
import numpy as np
import json
import torch.nn as nn

class CamembertClassifier(nn.Module):
    def __init__(self, num_classes):
        super(CamembertClassifier, self).__init__()
        self.camembert = CamembertModel.from_pretrained('camembert-base')
        self.dropout = nn.Dropout(0.2)
        self.fc1 = nn.Linear(768, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, num_classes)
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input_ids, attention_mask):
        outputs = self.camembert(input_ids=input_ids, attention_mask=attention_mask)
        cls_hs = outputs.last_hidden_state[:, 0]
        x = self.fc1(cls_hs)
        x = self.dropout(x)
        x = torch.relu(x)
        x = self.fc2(x)
        x = self.dropout(x)
        x = torch.relu(x)
        x = self.fc3(x)
        x = self.softmax(x)
        return x

def get_prediction(str):
  str = re.sub(r'[^a-zA-Z ]+', '', str)
  test_text = [str]
  model.eval()

  tokens_test_data = tokenizer(
  test_text,
  max_length = max_seq_len,
  padding=True,
  truncation=True,
  return_token_type_ids=False
  )
  test_seq = torch.tensor(tokens_test_data['input_ids'])
  test_mask = torch.tensor(tokens_test_data['attention_mask'])

  preds = None
  with torch.no_grad():
    preds = model(test_seq.to(), test_mask.to())
  preds = preds.detach().cpu().numpy()
  preds = np.argmax(preds, axis = 1)
  return le.inverse_transform(preds)[0]


#extraction des valeurs numerique

def extraire_valeurs(texte):
    valeurs = re.findall(r'\d+\.*\d*', texte)
    return [float(v) for v in valeurs]


def get_response(message):

    reponses={
        "tag":'',
        "valeur":[],
        "reponse":''
              }

    valeur=extraire_valeurs(message)
    reponses['valeur']=valeur

    intent = get_prediction(message)
    for i in data['intentions']:
        if i["tag"] == intent:
            reponses['tag']=intent
            result = random.choice(i["responses"])
            reponses['reponse']=result
            break
    else:
        result = "Désolé, je ne comprends pas bien votre question. Veuillez poser une autre question ou reformuler votre demande."

    # print(f"Response : {reponses}")
    # print( "Tag: " + str(intent) + '\n' + "Response: " + result)

    return reponses

# Charger le fichier JSON
with open('data.json', 'r') as f:
    data = json.load(f)

le = LabelEncoder()

# LabelEncoder
intentions = [i['tag'] for i in data['intentions']]
le.fit(intentions)

max_seq_len =250
tokenizer = CamembertTokenizer.from_pretrained('camembert-base')

# initialisation du modèle
num_classes = 43
model = CamembertClassifier(num_classes)


# Créer une nouvelle instance du modèle
model = CamembertClassifier(num_classes)

# Charger le state_dict
model.load_state_dict(torch.load('ModelChatBot/model.pth'))